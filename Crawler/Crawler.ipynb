{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Crawler Ruslan Sabirov.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "TFniucXbF6yM"
      },
      "source": [
        "# 1. Download and persist #\n",
        "Please complete a code for `load()`, `download()` and `persist()` methods of `Document` class. What they do:\n",
        "- for a given URL `download()` method downloads binary data and stores in `self.content`. It returns `True` for success, else `False`.\n",
        "- `persist()` method saves `self.content` somewhere. We do it to avoid multiple downloads.\n",
        "- `load()` method loads data from hard drive. Returns `True` for success.\n",
        "\n",
        "Tests checks that your code somehow works."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "rJukjSxdF6yP",
        "pycharm": {
          "is_executing": false
        },
        "colab": {}
      },
      "source": [
        "import requests\n",
        "import os\n",
        "from urllib.parse import quote, urlsplit\n",
        "\n",
        "class Document:\n",
        "    def __init__(self, url):\n",
        "        self.url = url\n",
        "        \n",
        "    def get(self):\n",
        "        if not self.load():\n",
        "            if not self.download():\n",
        "                raise FileNotFoundError(self.url)\n",
        "            else:\n",
        "                self.persist()\n",
        "    \n",
        "    def __get_filename(self):\n",
        "        name = str(hash(self.url))  # use the hash as a file name\n",
        "        return name\n",
        "    \n",
        "    def download(self):\n",
        "        try:\n",
        "            r = requests.get(self.url)\n",
        "            if r.status_code // 100 not in (2, 3):  # either 2.. or 3..\n",
        "                return False\n",
        "            self.content = r.content\n",
        "            return True\n",
        "        except Exception:\n",
        "            return False\n",
        "        \n",
        "    def persist(self):\n",
        "        if self.content is None:  # If there is nothing to save\n",
        "            return False\n",
        "        \n",
        "        file_name = self.__get_filename()\n",
        "        file = open(file_name, \"wb\")\n",
        "        file.write(self.content)\n",
        "        return True\n",
        "            \n",
        "    def load(self):\n",
        "        #TODO load content from hard drive, store it in self.content and return True in case of success\n",
        "        file_name = self.__get_filename()\n",
        "        if file_name not in os.listdir():  # if there is no such file the folder\n",
        "            return False\n",
        "        \n",
        "        file = open(file_name, \"rb\")\n",
        "        self.content = file.read()\n",
        "        return True"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "UBzWdF_GF6yT"
      },
      "source": [
        "## 1.1. Tests ##"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Q9FtiqtyF6yT",
        "pycharm": {
          "is_executing": false
        },
        "colab": {}
      },
      "source": [
        "doc = Document('http://sprotasov.ru/data/iu.txt')\n",
        "\n",
        "doc.get()\n",
        "assert doc.content, \"Document download failed\"\n",
        "assert \"Code snippets, demos and labs for the course\" in str(doc.content), \"Document content error\"\n",
        "\n",
        "doc.get()\n",
        "assert doc.load(), \"Load should return true for saved document\"\n",
        "assert \"Code snippets, demos and labs for the course\" in str(doc.content), \"Document load from disk error\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "J6QztytDF6yX"
      },
      "source": [
        "# 2. Parse HTML #\n",
        "`BeautifulSoap` library is a de facto standard to parse XML and HTML documents in python. Use it to complete `parse()` method that extracts document contents. You should initialize:\n",
        "- `self.anchors` list of tuples `('text', 'url')` met in a document. Be aware, there exist relative links. Use `urllib.parse.urljoin()` to fix this issue.\n",
        "- `self.images` list of images met in a document. Again links can be relative.\n",
        "- `self.text` should keep plain text of the document without scripts, tags, comments and so on. You can refer to [this stackoverflow answer](https://stackoverflow.com/a/1983219) for details."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "k2TqZrsTF6yY",
        "pycharm": {
          "is_executing": false
        },
        "colab": {}
      },
      "source": [
        "from bs4 import BeautifulSoup\n",
        "from bs4.element import Comment\n",
        "import urllib.parse\n",
        "import re\n",
        "\n",
        "\n",
        "class HtmlDocument(Document):\n",
        "    \n",
        "    def __tag_visible(self, element):\n",
        "        if element.parent.name in ['style', 'script', 'head', 'title', 'meta', '[document]']:\n",
        "            return False\n",
        "        if isinstance(element, Comment):\n",
        "            return False\n",
        "        return True\n",
        "    \n",
        "    def parse(self):\n",
        "        #TODO exctact plain text, images and links from the document\n",
        "        self.anchors = []\n",
        "        self.images = []\n",
        "        self.text = \"\"\n",
        "        \n",
        "        html_page = self.content\n",
        "        soup = BeautifulSoup(html_page)\n",
        "        \n",
        "        for link in soup.findAll('a', href=True):\n",
        "            if re.search(\"(tel)|(sms)|(mailto):\", link['href']) is None:  # if link contains neither 'tel:' nor 'sms:' nor 'mailto:'\n",
        "                full_link = urllib.parse.urljoin(self.url, link['href'])  # completes the link if it is relative\n",
        "                self.anchors.append((link.text, full_link))        \n",
        "            \n",
        "        for img in soup.findAll('img'):\n",
        "            link = urllib.parse.urljoin(self.url, img.get('src'))\n",
        "            self.images.append(link)\n",
        "        \n",
        "        for txt in soup.findAll(text=True):\n",
        "            if self.__tag_visible(txt):  # is tag is visible to user\n",
        "                self.text += txt\n",
        "        "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "QiWiAYhEF6yc"
      },
      "source": [
        "## 2.1. Tests ##"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ilZRPu9tF6ye",
        "pycharm": {
          "is_executing": false
        },
        "colab": {}
      },
      "source": [
        "doc = HtmlDocument(\"http://sprotasov.ru\")\n",
        "doc.get()\n",
        "doc.parse()\n",
        "\n",
        "assert \"тестирующий сервер codetest\" in doc.text, \"Error parsing text\"\n",
        "assert \"http://sprotasov.ru/images/phone.png\" in doc.images, \"Error parsing images\"\n",
        "assert any(p[1] == \"http://university.innopolis.ru/\" for p in doc.anchors), \"Error parsing links\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "DcYl7KyTF6yh"
      },
      "source": [
        "# 3. Document analysis #\n",
        "Complete the code for `HtmlDocumentTextData` class. Implement word (and sentence) splitting. Your `get_word_stats()` method should return `Counter` object. Don't forget to lowercase your words."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "60YJKACgF6yi",
        "pycharm": {
          "is_executing": false
        },
        "colab": {}
      },
      "source": [
        "from collections import Counter\n",
        "import re\n",
        "\n",
        "\n",
        "class HtmlDocumentTextData:\n",
        "    \n",
        "    def __init__(self, url):\n",
        "        self.doc = HtmlDocument(url)\n",
        "        self.doc.get()\n",
        "        self.doc.parse()\n",
        "    \n",
        "    def get_sentences(self):\n",
        "        txt = self.doc.text\n",
        "        txt = re.sub('[!@#$.\\-+*—,\\(\\):]', ' ', txt)  # replace all punctuation signs with spaces\n",
        "        txt = re.sub('[0-9]', ' ', txt)               # replace all digits with spaces\n",
        "        result = [x.lower() for x in txt.split()]     # lower all letters and delete all doubled spaces\n",
        "        return result\n",
        "    \n",
        "    def get_word_stats(self):\n",
        "        return Counter(self.get_sentences())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "auAOmjrZF6ym"
      },
      "source": [
        "## 3.1. Tests ##"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "jEGts6jTF6yn",
        "outputId": "3d3c7835-2b1e-48ce-f774-7fa1f927b30a",
        "pycharm": {
          "is_executing": false
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "doc = HtmlDocumentTextData(\"https://university.innopolis.ru\")\n",
        "\n",
        "print(doc.get_word_stats().most_common(10))\n",
        "assert [x for x in doc.get_word_stats().most_common(10) if x[0] == 'иннополис'], 'иннополис sould be among most common'"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('и', 62), ('в', 39), ('по', 34), ('иннополис', 31), ('на', 26), ('ул', 25), ('января', 20), ('университет', 16), ('ост', 16), ('со', 14)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ecLIp8tkF6yr"
      },
      "source": [
        "# 4. Crawling #\n",
        "\n",
        "Method `crawl_generator()` is given starting url (`source`) and max depth of search. It should return a **generator** of `HtmlDocumentTextData` objects (return a document as soon as it is downloaded and parsed). You can benefit from `yield obj_name` python construction. Use `HtmlDocumentTextData.anchors` field to go deeper."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "BYDfGWlkF6ys",
        "pycharm": {
          "is_executing": false
        },
        "colab": {}
      },
      "source": [
        "from queue import Queue\n",
        "\n",
        "\n",
        "class Crawler:\n",
        "    \n",
        "    def crawl_generator(self, source, depth=1):\n",
        "        #TODO return real crawling results. Don't forget to process failures\n",
        "        q = Queue()  # queue where pairs (url, depth) will be stored\n",
        "        q.put((source, 1)) \n",
        "        visited = set()  # set of visited urls\n",
        "\n",
        "        while not q.empty():  # while there are someting to proceed\n",
        "            try: \n",
        "                cur_url, cur_depth = q.get()\n",
        "\n",
        "                if \"#\" in cur_url:\n",
        "                    pos = cur_url.index(\"#\")\n",
        "                    cur_url = cur_url[:pos]\n",
        "                if cur_url in visited:  # no need to proceed already visited page\n",
        "                    continue\n",
        "                visited.add(cur_url)\n",
        "                \n",
        "                data = HtmlDocumentTextData(cur_url) \n",
        "                yield data\n",
        "\n",
        "                new_depth = cur_depth + 1\n",
        "                if new_depth <= depth:  # only if `new_depth` is not greater than argument `depth`\n",
        "                    for new_text, new_url in data.doc.anchors:  # proceed all tuples ('text', 'url')\n",
        "                        q.put((new_url, new_depth))  # add new pair to queue\n",
        "\n",
        "            except FileNotFoundError:\n",
        "                continue"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "_4aZu1H0F6yv"
      },
      "source": [
        "## 4.1. Tests ##"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "XqR_gCANF6yw",
        "outputId": "8c3c7f2f-5254-49fa-af45-6503c7e476fe",
        "pycharm": {
          "is_executing": false
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "crawler = Crawler()\n",
        "counter = Counter()\n",
        "print(\"starting\")\n",
        "for c in crawler.crawl_generator(\"https://university.innopolis.ru/en/\", 2):\n",
        "    print(c.doc.url)\n",
        "    if c.doc.url[-4:] in ('.pdf', '.mp3', '.avi', '.mp4', '.txt'):\n",
        "        print(\"Skipping\", c.doc.url)\n",
        "        continue\n",
        "    counter.update(c.get_word_stats())\n",
        "    print(len(counter), \"distinct word(s) so far\")\n",
        "    \n",
        "print(\"Done\")\n",
        "\n",
        "print(counter.most_common(20))\n",
        "assert [x for x in counter.most_common(20) if x[0] == 'innopolis'], 'innopolis sould be among most common'"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "starting\n",
            "https://university.innopolis.ru/en/\n",
            "408 distinct word(s) so far\n",
            "https://university.innopolis.ru/\n",
            "927 distinct word(s) so far\n",
            "https://university.innopolis.ru/en/?special=Y\n",
            "938 distinct word(s) so far\n",
            "https://university.innopolis.ru/en/about/\n",
            "1083 distinct word(s) so far\n",
            "https://university.innopolis.ru/en/about/city\n",
            "1148 distinct word(s) so far\n",
            "https://university.innopolis.ru/en/about/board\n",
            "1210 distinct word(s) so far\n",
            "https://university.innopolis.ru/en/about/job\n",
            "1475 distinct word(s) so far\n",
            "https://university.innopolis.ru/en/about/structure\n",
            "1613 distinct word(s) so far\n",
            "https://university.innopolis.ru/en/about/teaching-composition/\n",
            "1718 distinct word(s) so far\n",
            "https://university.innopolis.ru/upload/iblock/026/IU_AR2018_eng.pdf\n",
            "Skipping https://university.innopolis.ru/upload/iblock/026/IU_AR2018_eng.pdf\n",
            "https://university.innopolis.ru/en/education/\n",
            "1750 distinct word(s) so far\n",
            "https://university.innopolis.ru/en/education/bachelor/\n",
            "1781 distinct word(s) so far\n",
            "https://university.innopolis.ru/en/education/master/\n",
            "1793 distinct word(s) so far\n",
            "https://university.innopolis.ru/en/education/stem\n",
            "1862 distinct word(s) so far\n",
            "https://university.innopolis.ru/en/education/visit\n",
            "1893 distinct word(s) so far\n",
            "https://university.innopolis.ru/en/education/shadowing-program/\n",
            "1945 distinct word(s) so far\n",
            "https://university.innopolis.ru/en/research/\n",
            "1961 distinct word(s) so far\n",
            "https://university.innopolis.ru/en/research/competitions-and-grants/\n",
            "2006 distinct word(s) so far\n",
            "https://university.innopolis.ru/en/research/robotics/\n",
            "2071 distinct word(s) so far\n",
            "https://university.innopolis.ru/en/research/iis/\n",
            "2111 distinct word(s) so far\n",
            "https://university.innopolis.ru/en/research/itsd/\n",
            "2190 distinct word(s) so far\n",
            "https://university.innopolis.ru/en/cooperation/\n",
            "2195 distinct word(s) so far\n",
            "https://university.innopolis.ru/en/cooperation/global/\n",
            "2285 distinct word(s) so far\n",
            "https://university.innopolis.ru/en/cooperation/industry/\n",
            "2323 distinct word(s) so far\n",
            "https://apply.innopolis.ru/it-degrees-en/?utm_source=ui-en-slider&utm_medium=btn&utm_campaign=ui-site\n",
            "2368 distinct word(s) so far\n",
            "https://university.innopolis.ru/en/news/\n",
            "2368 distinct word(s) so far\n",
            "https://university.innopolis.ru/en/?TAGS=Industry\n",
            "2441 distinct word(s) so far\n",
            "https://university.innopolis.ru/en/?TAGS=Research\n",
            "2512 distinct word(s) so far\n",
            "https://university.innopolis.ru/en/?TAGS=Education\n",
            "2561 distinct word(s) so far\n",
            "https://university.innopolis.ru/en/?TAGS=Students life\n",
            "2628 distinct word(s) so far\n",
            "https://university.innopolis.ru/en/?TAGS=Global\n",
            "2657 distinct word(s) so far\n",
            "https://university.innopolis.ru/en/news/devops-summer-school/\n",
            "2717 distinct word(s) so far\n",
            "https://university.innopolis.ru/en/news/webinar-for-international-candidates-/\n",
            "2732 distinct word(s) so far\n",
            "https://university.innopolis.ru/en/news/registration-innopolis-open-2020/\n",
            "2754 distinct word(s) so far\n",
            "https://university.innopolis.ru/en/news/cyber-resilience-petrenko/\n",
            "2832 distinct word(s) so far\n",
            "https://university.innopolis.ru/en/news/innopolis-university-extends-international-application-deadline-/\n",
            "2872 distinct word(s) so far\n",
            "https://university.innopolis.ru/en/news/self-driven-school/\n",
            "2895 distinct word(s) so far\n",
            "https://university.innopolis.ru/en/news/webinar-for-international-candidates/\n",
            "2900 distinct word(s) so far\n",
            "https://university.innopolis.ru/en/news/the-first-release-for-testers-in-innopolis-university/\n",
            "2968 distinct word(s) so far\n",
            "https://university.innopolis.ru/en/?PAGEN_1=2&SIZEN_1=8\n",
            "2977 distinct word(s) so far\n",
            "https://university.innopolis.ru/en/?PAGEN_1=3&SIZEN_1=8\n",
            "2986 distinct word(s) so far\n",
            "https://university.innopolis.ru/en/?PAGEN_1=4&SIZEN_1=8\n",
            "3013 distinct word(s) so far\n",
            "https://university.innopolis.ru/en/?PAGEN_1=5&SIZEN_1=8\n",
            "3019 distinct word(s) so far\n",
            "https://university.innopolis.ru/en/?PAGEN_1=40&SIZEN_1=8\n",
            "3077 distinct word(s) so far\n",
            "https://university.innopolis.ru/en/?PAGEN_1=41&SIZEN_1=8\n",
            "3098 distinct word(s) so far\n",
            "http://english.corp.megafon.ru/\n",
            "3192 distinct word(s) so far\n",
            "http://www.vtb.com/\n",
            "3308 distinct word(s) so far\n",
            "http://rostec.ru/?lang=rus\n",
            "3523 distinct word(s) so far\n",
            "http://en.mts.ru/\n",
            "3768 distinct word(s) so far\n",
            "http://www.acronis.com/en-eu/\n",
            "4021 distinct word(s) so far\n",
            "http://www.parallels.com/\n",
            "4098 distinct word(s) so far\n",
            "http://www.icl.ru/web/guest\n",
            "4389 distinct word(s) so far\n",
            "http://at-consulting.co.uk/\n",
            "4427 distinct word(s) so far\n",
            "http://sin-x.ru/about/\n",
            "4575 distinct word(s) so far\n",
            "http://www.i-teco.ru/en/\n",
            "4878 distinct word(s) so far\n",
            "https://corp.mail.ru/en/\n",
            "4918 distinct word(s) so far\n",
            "http://xn--h1aax.xn--p1ai/\n",
            "4971 distinct word(s) so far\n",
            "http://etton.ru/\n",
            "5125 distinct word(s) so far\n",
            "http://www.infomatika.ru/\n",
            "5617 distinct word(s) so far\n",
            "https://kontur.ru/eng/about\n",
            "5719 distinct word(s) so far\n",
            "http://itpark-kazan.ru/ru/node/540\n",
            "5744 distinct word(s) so far\n",
            "http://cg.ru/\n",
            "5891 distinct word(s) so far\n",
            "https://www.bitrix24.com/\n",
            "5980 distinct word(s) so far\n",
            "http://rusenres.ru/\n",
            "6243 distinct word(s) so far\n",
            "http://maykor.com/en/\n",
            "6333 distinct word(s) so far\n",
            "http://www.russianpost.ru/rp/servise/en/home/postuslug/internationalmail/company\n",
            "6333 distinct word(s) so far\n",
            "http://www.kaspersky.co.uk/\n",
            "6520 distinct word(s) so far\n",
            "http://www.sberbank.ru/en/\n",
            "6720 distinct word(s) so far\n",
            "https://myoffice.ru/\n",
            "6960 distinct word(s) so far\n",
            "https://introscan.ru/\n",
            "7005 distinct word(s) so far\n",
            "http://www.informatics-europe.org/\n",
            "7073 distinct word(s) so far\n",
            "https://postgrespro.com/\n",
            "7213 distinct word(s) so far\n",
            "http://www.kuka-robotics.com/russia/ru/\n",
            "7560 distinct word(s) so far\n",
            "http://tatarstan.ru/eng/\n",
            "7616 distinct word(s) so far\n",
            "http://www.minsvyaz.ru/en/\n",
            "7669 distinct word(s) so far\n",
            "https://university.innopolis.ru/en/join-us/industry/\n",
            "7669 distinct word(s) so far\n",
            "http://www.innopolis.com/city/how-to-get/\n",
            "7845 distinct word(s) so far\n",
            "https://www.youtube.com/user/InnopolisU\n",
            "7887 distinct word(s) so far\n",
            "http://vk.com/innopolisu\n",
            "8029 distinct word(s) so far\n",
            "https://www.facebook.com/InnopolisU\n",
            "8149 distinct word(s) so far\n",
            "https://twitter.com/@InnopolisU\n",
            "8514 distinct word(s) so far\n",
            "http://habrahabr.ru/company/innopolis_university/\n",
            "8515 distinct word(s) so far\n",
            "https://docs.google.com/spreadsheets/d/139t1MN5hVdWQwpWh8oLUDMUcSou9XDyQvDUHilhKahc/pubhtml\n",
            "8597 distinct word(s) so far\n",
            "Done\n",
            "[('of', 2273), ('and', 1936), ('the', 1801), ('ул', 1136), ('university', 864), ('ост', 847), ('innopolis', 843), ('for', 801), ('in', 710), ('со', 579), ('to', 563), ('стороны', 560), ('institute', 494), ('education', 472), ('д', 468), ('a', 463), ('и', 421), ('research', 391), ('about', 357), ('маршрут', 356)]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}