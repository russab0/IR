{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "colab": {
      "name": "Language model template.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EADOJe6WQiCi",
        "colab_type": "text"
      },
      "source": [
        "# Language model\n",
        "\n",
        "Language model is a probability distribution over sequences of word.\n",
        "\n",
        "In this lab we will apply laguage model for a classification problem. The task is to implement a filter for spam documents.\n",
        "\n",
        "Read this article\n",
        "https://towardsdatascience.com/learning-nlp-language-models-with-real-data-cdff04c51c25"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lWK_ma1EQiCk",
        "colab_type": "text"
      },
      "source": [
        "### Dataset\n",
        "Download this https://www.kaggle.com/uciml/sms-spam-collection-dataset dataset.\n",
        "Normalize the text and split by sentences using nltk library. Split sentences to the terms. We don't need to do lemmatize words and remove stop words. For simplicity we will lose the punctuation and characters register.\n",
        "Make a lists of sentences for spam and ham messages."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0H0oMF9-VTzV",
        "colab_type": "code",
        "outputId": "8ed01aa8-107b-414a-b05d-d41fc6e4bc46",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        }
      },
      "source": [
        "from plotly.offline import init_notebook_mode\n",
        "init_notebook_mode(connected=True)\n",
        "from IPython.core.interactiveshell import InteractiveShell\n",
        "InteractiveShell.ast_node_interactivity = \"all\""
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "        <script type=\"text/javascript\">\n",
              "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
              "        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
              "        if (typeof require !== 'undefined') {\n",
              "        require.undef(\"plotly\");\n",
              "        requirejs.config({\n",
              "            paths: {\n",
              "                'plotly': ['https://cdn.plot.ly/plotly-latest.min']\n",
              "            }\n",
              "        });\n",
              "        require(['plotly'], function(Plotly) {\n",
              "            window._Plotly = Plotly;\n",
              "        });\n",
              "        }\n",
              "        </script>\n",
              "        "
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PYCYC9bVQiCl",
        "colab_type": "code",
        "outputId": "89293f8e-9a4d-4767-8601-f87919931fc1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "import pandas as pd\n",
        "import nltk\n",
        "\n",
        "from itertools import chain\n",
        "import re\n",
        "\n",
        "df = pd.read_csv('spam.csv', encoding = 'ISO-8859-1')[['v1', 'v2']]\n",
        "df.rename(columns={'v1': 'type', 'v2': 'content'}, inplace=True)\n",
        "df.head()\n",
        "\n",
        "spam_messages = df[df['type'] == 'spam']['content'].tolist() #list of sentences, each sentence represented as a list of terms\n",
        "ham_messages = df[df['type'] == 'ham']['content'].tolist()\n",
        "\n",
        "len(spam_messages), len(ham_messages)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>type</th>\n",
              "      <th>content</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ham</td>\n",
              "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ham</td>\n",
              "      <td>Ok lar... Joking wif u oni...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>spam</td>\n",
              "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ham</td>\n",
              "      <td>U dun say so early hor... U c already then say...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ham</td>\n",
              "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   type                                            content\n",
              "0   ham  Go until jurong point, crazy.. Available only ...\n",
              "1   ham                      Ok lar... Joking wif u oni...\n",
              "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
              "3   ham  U dun say so early hor... U c already then say...\n",
              "4   ham  Nah I don't think he goes to usf, he lives aro..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(747, 4825)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eaIc5nrkgH3R",
        "colab_type": "code",
        "outputId": "dd09115d-92b2-4ee3-c09c-1a88d9122528",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "spam_messages[0:5]"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[\"Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive entry question(std txt rate)T&C's apply 08452810075over18's\",\n",
              " \"FreeMsg Hey there darling it's been 3 week's now and no word back! I'd like some fun you up for it still? Tb ok! XxX std chgs to send, å£1.50 to rcv\",\n",
              " 'WINNER!! As a valued network customer you have been selected to receivea å£900 prize reward! To claim call 09061701461. Claim code KL341. Valid 12 hours only.',\n",
              " 'Had your mobile 11 months or more? U R entitled to Update to the latest colour mobiles with camera for Free! Call The Mobile Update Co FREE on 08002986030',\n",
              " 'SIX chances to win CASH! From 100 to 20,000 pounds txt> CSH11 and send to 87575. Cost 150p/day, 6days, 16+ TsandCs apply Reply HL 4 info']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PVfqx8d-QiCr",
        "colab_type": "text"
      },
      "source": [
        "Print the average length and average number of sentences in spam message."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I7z_F6adQiCs",
        "colab_type": "code",
        "outputId": "13bd9cda-3405-49af-c08b-49993f14e9e2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "from nltk.tokenize import sent_tokenize, word_tokenize\n",
        "_ = nltk.download('punkt')\n",
        "\n",
        "sent_sizes = [len(word_tokenize(sent)) for msg in spam_messages for sent in sent_tokenize(msg)]\n",
        "avg_sent_len = sum(sent_sizes) / len(sent_sizes)\n",
        "\n",
        "avg_sent_num = sum([len(sent_tokenize(msg)) for msg in spam_messages]) / len(spam_messages)\n",
        "\n",
        "print(f'Average sentence length: {avg_sent_len:.2f}, average num of sent: {avg_sent_num:.2f}')"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "Average sentence length: 9.17, average num of sent: 3.02\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IdJMIe6SZQxJ",
        "colab_type": "code",
        "outputId": "9eedaf6c-d6f3-478c-96e5-dd27e409db33",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        }
      },
      "source": [
        "import string\n",
        "\n",
        "PUNCT = string.punctuation + '“”«»—•\\\\/'\n",
        "\n",
        "def normalize(text, allow_asterix=False):\n",
        "    text = text.lower()\n",
        "    text = re.sub('\\'', '', text)                          # remove apostrophes\n",
        "    #text = re.sub('[!\\?@#$.\\-+=><—,\\(\\)&:“”]', ' ', text)        # replace all punctuation signs with spaces\n",
        "    text = re.sub(f'[{PUNCT}]', ' ', text)        # replace all punctuation signs with spaces\n",
        "    \n",
        "    if not allow_asterix:\n",
        "        text = re.sub('\\*', ' ', text)                      # replace all astrixes (*) with spaces\n",
        "    text = re.sub('[0-9]', ' ', text)                      # replace all digits with spaces\n",
        "    result = \" \".join([x.lower() for x in text.split()])   # lower all letters and delete all doubled spaces\n",
        "    return result\n",
        "\n",
        "def messages_to_sentences(messages):\n",
        "    return list(chain(\n",
        "        *[[word_tokenize(normalize(sent)) for sent in sent_tokenize(msg)] for msg in messages]))\n",
        "\n",
        "spam_sentences = messages_to_sentences(spam_messages)\n",
        "ham_sentences = messages_to_sentences(ham_messages)\n",
        "\n",
        "for i in range(10):\n",
        "    print(spam_sentences[i])"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['free', 'entry', 'in', 'a', 'wkly', 'comp', 'to', 'win', 'fa', 'cup', 'final', 'tkts', 'st', 'may']\n",
            "['text', 'fa', 'to', 'to', 'receive', 'entry', 'question', 'std', 'txt', 'rate', 't', 'cs', 'apply', 'over', 's']\n",
            "['freemsg', 'hey', 'there', 'darling', 'its', 'been', 'weeks', 'now', 'and', 'no', 'word', 'back']\n",
            "['id', 'like', 'some', 'fun', 'you', 'up', 'for', 'it', 'still']\n",
            "['tb', 'ok']\n",
            "['xxx', 'std', 'chgs', 'to', 'send', 'å£', 'to', 'rcv']\n",
            "['winner']\n",
            "['as', 'a', 'valued', 'network', 'customer', 'you', 'have', 'been', 'selected', 'to', 'receivea', 'å£', 'prize', 'reward']\n",
            "['to', 'claim', 'call']\n",
            "['claim', 'code', 'kl']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gzCcgLJUQiCw",
        "colab_type": "text"
      },
      "source": [
        "### Unigram model\n",
        "\n",
        "Calculate the number of occurancies of each term separately for spam and ham messages. \n",
        "\n",
        "Calculate the total number of terms."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yKTLJs3e27fo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from collections import Counter\n",
        "\n",
        "class CountDict(Counter):\n",
        "    \"\"\"\n",
        "    Class that is used as counter, inherited from dict. \n",
        "    \"\"\"\n",
        "    def __getitem__(self, item):\n",
        "        \"\"\"\n",
        "        Gets item without exceptions\n",
        "        :param item:  key you want to get\n",
        "        :return: value, associated with `item` (if item in the `keys`), 0 otherwise\n",
        "        \"\"\"\n",
        "        if item not in self:\n",
        "            return 0\n",
        "        return super().__getitem__(item)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XjPshtGAQiCw",
        "colab_type": "raw"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fMIydOrEQiCx",
        "colab_type": "code",
        "outputId": "a755e04d-4484-4b0a-94cf-21a662ce98cd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "START = 'START'\n",
        "END = 'END'\n",
        "\n",
        "spam_term_c = CountDict(Counter(list(chain(*spam_sentences))))  # dict()\n",
        "spam_term_c[START] = spam_term_c[END] = len(spam_sentences)\n",
        "spam_N = sum(spam_term_c.values())\n",
        "\n",
        "ham_term_c = CountDict(Counter(list(chain(*ham_sentences))))  # dict()\n",
        "ham_term_c[START] = ham_term_c[END] = len(ham_sentences)\n",
        "ham_N = sum(ham_term_c.values())\n",
        "\n",
        "spam_N, ham_N"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(21863, 86107)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zvWYqoX7QiC4",
        "colab_type": "text"
      },
      "source": [
        "Print 10 most popular words in spam messages."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qb_q5e-qQiC5",
        "colab_type": "code",
        "outputId": "4a87813d-7cc3-4e0c-b22e-64a882cdd825",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "'Spam most popular words', spam_term_c.most_common(10)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('Spam most popular words',\n",
              " [('START', 2256),\n",
              "  ('END', 2256),\n",
              "  ('to', 688),\n",
              "  ('a', 390),\n",
              "  ('call', 370),\n",
              "  ('å£', 299),\n",
              "  ('you', 291),\n",
              "  ('your', 264),\n",
              "  ('free', 228),\n",
              "  ('the', 206)])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b3C-iODcl4io",
        "colab_type": "code",
        "outputId": "1cde0f92-e7dd-444d-d915-e62d95211870",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "'Ham most popular words', ham_term_c.most_common(10)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('Ham most popular words',\n",
              " [('START', 8841),\n",
              "  ('END', 8841),\n",
              "  ('i', 2295),\n",
              "  ('you', 1858),\n",
              "  ('to', 1554),\n",
              "  ('the', 1124),\n",
              "  ('a', 1055),\n",
              "  ('u', 1010),\n",
              "  ('and', 857),\n",
              "  ('in', 820)])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LsvQNQfSQiC_",
        "colab_type": "text"
      },
      "source": [
        "### Bigram model\n",
        "\n",
        "We will use sentence begining and sentence ending as a special terms. Calculate the number of occuracnies for bigrams. As a key in dictionary you might use words, separated by the space symbol.\n",
        "\n",
        "Also, for a genetative model, epxlained later, for each term we will need a list of next term, found in the dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nyaD4uLcQiDA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def bigram_nextword(sentences):\n",
        "    bigrams = CountDict()\n",
        "    next_words = dict()\n",
        "    for i in range(len(sentences)):\n",
        "        sent = [START] + sentences[i] + [END]\n",
        "        for cur_token_pos in range(len(sent) - 1):\n",
        "            cur_token, next_token = sent[cur_token_pos:cur_token_pos + 2]\n",
        "            bigram = cur_token + ' ' + next_token\n",
        "            if not bigram in bigrams:\n",
        "                bigrams[bigram] = 0\n",
        "            bigrams[bigram] += 1\n",
        "            \n",
        "            if not cur_token in next_words:\n",
        "                next_words[cur_token] = set()\n",
        "            next_words[cur_token].add(next_token)\n",
        "    for k in next_words:\n",
        "        next_words[k] = list(next_words[k]) \n",
        "    return bigrams, next_words\n",
        "\n",
        "spam_bigram_c, spam_next_words = bigram_nextword(spam_sentences)\n",
        "ham_bigram_c, _ = bigram_nextword(spam_sentences)\n",
        "\n",
        "spam_bi_N = sum(spam_bigram_c.values())\n",
        "ham_bi_N = sum(ham_bigram_c.values())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mDziH8I7QiDG",
        "colab_type": "text"
      },
      "source": [
        "Which bigrams are the most popular in spam messages?\n",
        "\n",
        "From which words spam sentence usually begins?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vAQQKHWGQiDI",
        "colab_type": "code",
        "outputId": "a2b67056-8dd2-4508-eb17-21f67ff4816a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        }
      },
      "source": [
        "spam_bigram_pop = sorted(list(spam_bigram_c.items()), \n",
        "                         key=lambda x: x[1],\n",
        "                         reverse=True\n",
        "                         )[:10]\n",
        "\n",
        "spam_bigram_start_pop = sorted(\n",
        "    [x for x in spam_bigram_c.items() if x[0].startswith(START)],\n",
        "    key=lambda x: x[1],\n",
        "    reverse=True\n",
        "    )[:10]\n",
        "\n",
        "spam_bigram_pop, spam_bigram_start_pop"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "([('START call', 149),\n",
              "  ('now END', 103),\n",
              "  ('START you', 80),\n",
              "  ('you have', 73),\n",
              "  ('to END', 73),\n",
              "  ('a å£', 73),\n",
              "  ('START your', 67),\n",
              "  ('START to', 66),\n",
              "  ('START txt', 61),\n",
              "  ('call now', 59)],\n",
              " [('START call', 149),\n",
              "  ('START you', 80),\n",
              "  ('START your', 67),\n",
              "  ('START to', 66),\n",
              "  ('START txt', 61),\n",
              "  ('START urgent', 54),\n",
              "  ('START free', 47),\n",
              "  ('START text', 40),\n",
              "  ('START claim', 38),\n",
              "  ('START reply', 37)])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hx0iEmIgQiDN",
        "colab_type": "text"
      },
      "source": [
        "Implement a function, which return the conditional probability $P(t_2 | t_1) = \\frac{count(t_1 t_2)}{count(t_1)}$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sT0Q-DVlQiDO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def conditional_prob(t1, t2, spam=True):\n",
        "    bigram = t1 + ' ' + t2\n",
        "    if spam:\n",
        "        if spam_bigram_c[bigram] * spam_term_c[t1] == 0:\n",
        "            return 0\n",
        "        return spam_bigram_c[bigram] / spam_term_c[t1]\n",
        "    else:\n",
        "        #print(t1, t2, ham_bigram_c[bigram], ham_term_c[t1])\n",
        "        if ham_bigram_c[bigram] * ham_term_c[t1] == 0:\n",
        "            return 0\n",
        "        return ham_bigram_c[bigram] / ham_term_c[t1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QH0ierLCQiDT",
        "colab_type": "text"
      },
      "source": [
        "### Genetative model\n",
        "\n",
        "Now is the funny task. Using your language model generate a spam message. Remember you calculated the average number of sentences, average sentence size for spam messages.\n",
        "\n",
        "Print few generated ouptuts.\n",
        "\n",
        "#### Interesting outputs\n",
        "\n",
        "- `Urgent. Reply or å£ cash every week. You are trying to no prepayment`\n",
        "- `Win a guaranteed. Txt chat on orange line rental camcorder hit. Stop to contact u been renewed and downloads`\n",
        "- `Free top quality ringtone club credits pls reply. Just txt great graphics from landline box croydon. Urgent`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fINb1Xm9QiDU",
        "colab_type": "code",
        "outputId": "fd7e195e-7e3f-4db6-b507-3b18c45de123",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from random import random, choice, seed, randint\n",
        "import numpy as np\n",
        "\n",
        "seed(1)\n",
        "np.random.seed(1)\n",
        "\n",
        "def generate_sentence(bigrams, next_words, sent_size):\n",
        "    sent = []\n",
        "    prev_word = START\n",
        "    for j in range(round(sent_size)):\n",
        "        if prev_word == END:\n",
        "            break\n",
        "        possible = next_words[prev_word]\n",
        "        pdf = np.array([conditional_prob(prev_word, word) for word in possible])\n",
        "        cdf = np.cumsum(pdf)\n",
        "\n",
        "        cur_word = possible[0]\n",
        "        r = random()\n",
        "        for i in range(len(cdf)):\n",
        "            if cdf[i] > r:\n",
        "                cur_word = possible[i]\n",
        "                break\n",
        "        sent.append(cur_word)\n",
        "        prev_word = cur_word\n",
        "        \n",
        "    sent[0] = sent[0].capitalize()\n",
        "    return ' '.join(sent[:-1])\n",
        "\n",
        "def generate(bigrams, next_words, sent_size, sent_num):\n",
        "    text = [\n",
        "            generate_sentence(bigrams, next_words, sent_size)\n",
        "            for _ in range(round(sent_num))\n",
        "    ]\n",
        "    return '. '.join(text)\n",
        "\n",
        "for i in range(5):\n",
        "    print(generate(spam_bigram_c, spam_next_words, avg_sent_len, avg_sent_num))"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Hi babe to send nokia to. Xmas reward of jordan txt swap and up. Sunshine\n",
            "Free game å£ of discount vouchers. Yrs only with a å£ this is the. Spook to maximize ur smart though this weeks\n",
            "Cost p mt msgrcvd skip an urgent. Call. U will receive å£ bonus caller prize\n",
            "Call free. Money over. Private\n",
            "We have new mobile for euro stop to. Im i put you are the following service. Txt or a sim subscriber ur games arcade\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fY-OaPXeQiDZ",
        "colab_type": "text"
      },
      "source": [
        "### Smoothing\n",
        "\n",
        "The problem is that if the bigram $t_1 t_2$ occuted $0$ times in the corpus, the conditional probability $P(t_2|t_1) = 0$\n",
        "\n",
        "The solution is smoothing. Read this document https://nlp.stanford.edu/~wcmac/papers/20050421-smoothing-tutorial.pdf\n",
        "\n",
        "Your task is to implement one of the advanced (from the document, except additive smoothing) smoothing techniques from it. Be ready to explain it defending the lab.\n",
        "\n",
        "Implement a function, which return the conditional probability $P(t_2 | t_1)$ with a smoothing.\n",
        "\n",
        "### Jelinek-Mercer smoothing (interpolation)\n",
        "\n",
        "$P(t_2 | t_1) = \\lambda \\cdot \\frac{count(t_1 t_2)}{count(t_1)} + (1 - \\lambda) \\cdot \\frac{count(t_1)}{\\sum_{i=0}^{M} count(t_i)} $"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PrxddtlwQiDa",
        "colab_type": "code",
        "outputId": "55920f2a-d67a-40a3-98ac-1cfc246688aa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "def unigram_prob(t, spam=True, lamb=0.5):\n",
        "    if spam:\n",
        "        return lamb * spam_term_c[t] / spam_N + (1 - lamb) / spam_N\n",
        "    else:\n",
        "        return lamb * ham_term_c[t] / ham_N + (1 - lamb) / ham_N\n",
        "\n",
        "def bigram_prob(t1, t2, spam=True, lamb=0.5):\n",
        "    return lamb * conditional_prob(t1, t2, spam) + (1 - lamb) * unigram_prob(t2)\n",
        "\n",
        "def smoothing_conditional_prob(t1, t2, spam=True, lamb=0.5):\n",
        "    # Jelinek-Mercer smoothing (interpolation)\n",
        "    return bigram_prob(t1, t2, spam, lamb)\n",
        "\n",
        "t1, t2 = choice(list(spam_bigram_c.keys())).split()\n",
        "t1, t2,\n",
        "for lamb in np.linspace(0, 1, num=11):\n",
        "    print(f'lambda= {lamb:.1f}, smoothing_cond_prob= {smoothing_conditional_prob(t1, t2, True, lamb):.2f}')"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('then', 'text')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        },
        {
          "output_type": "stream",
          "text": [
            "lambda= 0.0, smoothing_cond_prob= 0.00\n",
            "lambda= 0.1, smoothing_cond_prob= 0.02\n",
            "lambda= 0.2, smoothing_cond_prob= 0.04\n",
            "lambda= 0.3, smoothing_cond_prob= 0.06\n",
            "lambda= 0.4, smoothing_cond_prob= 0.08\n",
            "lambda= 0.5, smoothing_cond_prob= 0.10\n",
            "lambda= 0.6, smoothing_cond_prob= 0.12\n",
            "lambda= 0.7, smoothing_cond_prob= 0.14\n",
            "lambda= 0.8, smoothing_cond_prob= 0.16\n",
            "lambda= 0.9, smoothing_cond_prob= 0.18\n",
            "lambda= 1.0, smoothing_cond_prob= 0.20\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i-9XiRYrQiDe",
        "colab_type": "text"
      },
      "source": [
        "### Classification\n",
        "\n",
        "Now, implement a bayessian classifier for the sentence. Test one of your generated sentences on it.\n",
        "\n",
        "It should return, which probability is higher\n",
        "\n",
        "$$P(spam|t_1, \\dots , t_k) = \\frac{P(t_1, \\dots , t_k|spam)P(spam)}{P(t_1, \\dots , t_k)} \\sim P(t_1, \\dots , t_k|spam)P(spam)$$ \n",
        "$$\\sim P(t_1 | BEGIN, spam) \\cdot \\sim P(t_2 | t_1, spam) \\cdot \\dots \\cdot \\sim P(END | t_k, spam)$$\n",
        "\n",
        "or the same for ham sentence."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ejvUYqNRQiDf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from termcolor import colored\n",
        "\n",
        "EPS = 10 ** (-20)\n",
        "\n",
        "def classification_prob(sentence, spam, lamb=0.5):\n",
        "    if isinstance(sentence, str):\n",
        "        sentence = word_tokenize(sentence)\n",
        "    sentence_bigrams = [(sentence[i], sentence[i + 1])\n",
        "                        for i in range(len(sentence) - 1)]\n",
        "    return np.prod([\n",
        "                    smoothing_conditional_prob(bi[0], bi[1], spam, lamb)\n",
        "                    for bi in sentence_bigrams\n",
        "    ])\n",
        "\n",
        "\n",
        "def classify(sentence, lamb=0.5):\n",
        "    spam_prob = classification_prob(sentence, spam=True, lamb=lamb)\n",
        "    ham_prob = classification_prob(sentence, spam=False, lamb=lamb)\n",
        "    \n",
        "    #if abs(spam_prob - ham_prob) < EPS: # with this it classifies much worse\n",
        "    #    return 'same'\n",
        "    if spam_prob > ham_prob:\n",
        "        return 'spam'\n",
        "    return 'ham'\n",
        "\n",
        "\n",
        "def colorify(r):\n",
        "    if r == 'same':\n",
        "        return colored('same', 'blue')\n",
        "    if r == 'spam':\n",
        "        return colored('spam', 'red')\n",
        "    return colored('ham', 'green')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HKms-mUDIzLb",
        "colab_type": "code",
        "outputId": "bc93737e-867d-404c-e3c8-29464ef6d174",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        }
      },
      "source": [
        "from sklearn.metrics import balanced_accuracy_score\n",
        "\n",
        "best_lamb = 0\n",
        "best_score = 0\n",
        "for lamb in np.linspace(0.0, 1.0, num=20):\n",
        "    y_pred = [classify(sent, lamb) for sent in spam_sentences + ham_sentences]\n",
        "    y_true = ['spam'] * len(spam_sentences) + ['ham'] * len(ham_sentences)\n",
        "    score = balanced_accuracy_score(y_true, y_pred)\n",
        "    if score > best_score:\n",
        "        best_score = score\n",
        "        best_lamb = lamb\n",
        "    print(f'lambda= {lamb:.2f}, score= {score:.5f}')"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "lambda= 0.00, score= 0.50000\n",
            "lambda= 0.05, score= 0.59250\n",
            "lambda= 0.11, score= 0.60779\n",
            "lambda= 0.16, score= 0.61610\n",
            "lambda= 0.21, score= 0.61959\n",
            "lambda= 0.26, score= 0.62236\n",
            "lambda= 0.32, score= 0.62413\n",
            "lambda= 0.37, score= 0.62845\n",
            "lambda= 0.42, score= 0.62972\n",
            "lambda= 0.47, score= 0.63388\n",
            "lambda= 0.53, score= 0.63443\n",
            "lambda= 0.58, score= 0.63532\n",
            "lambda= 0.63, score= 0.63725\n",
            "lambda= 0.68, score= 0.63903\n",
            "lambda= 0.74, score= 0.64030\n",
            "lambda= 0.79, score= 0.64252\n",
            "lambda= 0.84, score= 0.64363\n",
            "lambda= 0.89, score= 0.64363\n",
            "lambda= 0.95, score= 0.64518\n",
            "lambda= 1.00, score= 0.87569\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b0U5ufoIIyYM",
        "colab_type": "code",
        "outputId": "3579f239-2e34-40d5-c280-1bccce536d8b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        }
      },
      "source": [
        "print(\"ACTUALLY SPAM\")\n",
        "for i in range(10):\n",
        "    k = randint(0, len(spam_sentences))\n",
        "    pred = colorify(classify(spam_sentences[k], best_lamb))\n",
        "    print(pred, spam_sentences[k])\n",
        "\n",
        "\n",
        "print(\"\\nACTUALLY HAM\")\n",
        "for i in range(10):\n",
        "    k = randint(0, len(ham_sentences))\n",
        "    pred = colorify(classify(ham_sentences[k], best_lamb))\n",
        "    print(pred, ham_sentences[k])"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ACTUALLY SPAM\n",
            "\u001b[31mspam\u001b[0m ['call', 'from', 'land', 'line']\n",
            "\u001b[31mspam\u001b[0m ['freemsg', 'fancy', 'a', 'flirt']\n",
            "\u001b[31mspam\u001b[0m ['you', 'have', 'new', 'message']\n",
            "\u001b[31mspam\u001b[0m ['mila', 'age', 'blonde', 'new', 'in', 'uk']\n",
            "\u001b[31mspam\u001b[0m ['claim', 'is', 'easy', 'just', 'call', 'now']\n",
            "\u001b[31mspam\u001b[0m ['cc', 'hg', 'suite', 'lands', 'row', 'w', 'j', 'hl']\n",
            "\u001b[31mspam\u001b[0m ['your', 'å£', 'prize', 'from', 'yesterday', 'is', 'still', 'awaiting', 'collection']\n",
            "\u001b[32mham\u001b[0m ['congrats']\n",
            "\u001b[31mspam\u001b[0m ['we', 'are', 'trying', 'to', 'contact', 'you']\n",
            "\u001b[31mspam\u001b[0m ['u', 'up', 'for', 'some', 'fun']\n",
            "\n",
            "ACTUALLY HAM\n",
            "\u001b[32mham\u001b[0m ['darren', 'is', 'wif', 'them', 'now']\n",
            "\u001b[32mham\u001b[0m ['how', 'r', 'u', 'man']\n",
            "\u001b[32mham\u001b[0m ['yes']\n",
            "\u001b[32mham\u001b[0m ['the', 'battery', 'is', 'for', 'mr', 'adewale', 'my', 'uncle']\n",
            "\u001b[32mham\u001b[0m ['am', 'on', 'a', 'train', 'back', 'from', 'northampton', 'so', 'im', 'afraid', 'not']\n",
            "\u001b[32mham\u001b[0m ['and', 'is', 'there', 'a', 'way', 'you', 'can', 'send', 'shades', 'stuff', 'to', 'her']\n",
            "\u001b[32mham\u001b[0m ['did', 'u', 'do', 'anything', 'with', 'website']\n",
            "\u001b[32mham\u001b[0m []\n",
            "\u001b[32mham\u001b[0m ['all', 'will', 'be', 'well', 'in', 'a', 'few', 'months']\n",
            "\u001b[32mham\u001b[0m ['haiz']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z8JyL8SpQuAN",
        "colab_type": "text"
      },
      "source": [
        "## Funny application\n",
        "Super Innopolis messages generator bot: [@SuperInnoMsgBot](https://teleg.run/SuperInnoMsgBot)\n"
      ]
    }
  ]
}